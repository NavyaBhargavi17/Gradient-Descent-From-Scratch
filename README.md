# Gradient-Descent-From-Scratch
A simple implementation of Gradient Descent and Cost Function using Python with CSV dataset.
Gradient Descent from Scratch
ğŸ“Œ Project Overview
This project demonstrates Gradient Descent and Cost Function for a simple linear regression problem using a small CSV dataset.
We implement gradient descent from scratch (without using sklearn) to find the best-fit line for a dataset of Hours vs Marks.

ğŸš€ Features
Implements Mean Squared Error (MSE) as the cost function.

Updates slope (m) and intercept (b) using Gradient Descent.

Visualizes:

The dataset (scatter plot).

The best-fit line after training.

Works with data loaded from a CSV file.

ğŸ—‚ Dataset
The dataset used is data.csv:

css
Copy
Edit
Hours,Marks
1,2
2,4
3,6
4,8
5,10

ğŸ“œ Project Files
gradient_descent.ipynb â€“ Google Colab notebook with step-by-step code.

data.csv â€“ Dataset (Hours vs Marks).

README.md â€“ Project details.

âš™ï¸ How to Run
Open the notebook in Google Colab or Jupyter.

Upload data.csv.

Run all cells to:

Load data.

Compute cost function.

Run gradient descent for 100 iterations.

Visualize the final line.

ğŸ“Š Output Example
Final Equation:
y = 2.00x + 0.00

Visualization:
A scatter plot of points with a red best-fit line.

ğŸŒŸ Future Improvements
Add animation for line movement during gradient descent.

Apply to a larger dataset (e.g., house prices).

Compare with sklearnâ€™s LinearRegression.

ğŸ‘©â€ğŸ’» Author
Navya Bhargavi
Future Full Stack Developer in AI/ML
