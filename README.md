# Gradient-Descent-From-Scratch
A simple implementation of Gradient Descent and Cost Function using Python with CSV dataset.
Gradient Descent from Scratch
📌 Project Overview
This project demonstrates Gradient Descent and Cost Function for a simple linear regression problem using a small CSV dataset.
We implement gradient descent from scratch (without using sklearn) to find the best-fit line for a dataset of Hours vs Marks.

🚀 Features
Implements Mean Squared Error (MSE) as the cost function.

Updates slope (m) and intercept (b) using Gradient Descent.

Visualizes:

The dataset (scatter plot).

The best-fit line after training.

Works with data loaded from a CSV file.

🗂 Dataset
The dataset used is data.csv:

css
Copy
Edit
Hours,Marks
1,2
2,4
3,6
4,8
5,10

📜 Project Files
gradient_descent.ipynb – Google Colab notebook with step-by-step code.

data.csv – Dataset (Hours vs Marks).

README.md – Project details.

⚙️ How to Run
Open the notebook in Google Colab or Jupyter.

Upload data.csv.

Run all cells to:

Load data.

Compute cost function.

Run gradient descent for 100 iterations.

Visualize the final line.

📊 Output Example
Final Equation:
y = 2.00x + 0.00

Visualization:
A scatter plot of points with a red best-fit line.

🌟 Future Improvements
Add animation for line movement during gradient descent.

Apply to a larger dataset (e.g., house prices).

Compare with sklearn’s LinearRegression.

👩‍💻 Author
Navya Bhargavi
Future Full Stack Developer in AI/ML
